{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from scikit-learn) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: xgboost in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from xgboost) (2.0.2)\n",
      "Requirement already satisfied: scipy in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas matplotlib\n",
    "%pip install scikit-learn\n",
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sampleData/master_orders.csv\")\n",
    "df[\"Order Date\"] = pd.to_datetime(df[\"Order Date\"], utc=True)\n",
    "df = df.sort_values(\"Order Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17684 entries, 17563 to 1685\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   Order Date     17506 non-null  datetime64[ns, UTC]\n",
      " 1   SKU            16507 non-null  object             \n",
      " 2   Item           17683 non-null  object             \n",
      " 3   Variant        14338 non-null  object             \n",
      " 4   Quantity       17663 non-null  float64            \n",
      " 5   Delivery Date  11825 non-null  object             \n",
      " 6   Delivery Time  11573 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), object(5)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate based on monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = (\n",
    "    df\n",
    "    .set_index(\"Order Date\")\n",
    "    .groupby([\"SKU\", pd.Grouper(freq=\"ME\")])[\"Quantity\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"Order Date\": \"Month\"})\n",
    "    .sort_values([\"SKU\", \"Month\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly[\"month_num\"] = monthly[\"Month\"].dt.month\n",
    "\n",
    "monthly[\"year\"] = monthly[\"Month\"].dt.year\n",
    "\n",
    "monthly[\"sku_id\"] = monthly[\"SKU\"].astype(\"category\").cat.codes\n",
    "\n",
    "# demand lag by x months\n",
    "monthly[\"lag_1\"] = monthly.groupby(\"SKU\")[\"Quantity\"].shift(1)\n",
    "monthly[\"lag_2\"] = monthly.groupby(\"SKU\")[\"Quantity\"].shift(2)\n",
    "monthly[\"lag_3\"] = monthly.groupby(\"SKU\")[\"Quantity\"].shift(3)\n",
    "\n",
    "# month sin/cos seasonality\n",
    "monthly[\"month_sin\"] = np.sin(2 * np.pi * monthly[\"month_num\"] / 12)\n",
    "monthly[\"month_cos\"] = np.cos(2 * np.pi * monthly[\"month_num\"] / 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get top 5 SKUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>total_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SF50</td>\n",
       "      <td>5108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CU-1</td>\n",
       "      <td>1423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SC5</td>\n",
       "      <td>674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR50</td>\n",
       "      <td>592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SC15</td>\n",
       "      <td>538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SKU  total_qty\n",
       "0  SF50     5108.0\n",
       "1  CU-1     1423.0\n",
       "2   SC5      674.0\n",
       "3  DR50      592.0\n",
       "4  SC15      538.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_df = (\n",
    "    monthly.groupby(\"SKU\", observed=True)[\"Quantity\"]\n",
    "    .sum()\n",
    "    .rename(\"total_qty\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "vol_df = vol_df.sort_values([\"total_qty\", \"SKU\"], ascending=[False, True], kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "vol_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5 = vol_df.head(top_k)[\"SKU\"].tolist()\n",
    "top5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratify SKUs into sales volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_df = vol_df[~vol_df[\"SKU\"].isin(top5)].copy()\n",
    "rest_total = rest_df[\"total_qty\"].sum()\n",
    "\n",
    "rest_df[\"cum_share\"] = rest_df[\"total_qty\"].cumsum() / rest_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins   = [-np.inf, 0.70, 0.95, np.inf]\n",
    "labels = [\"highest\", \"medium\", \"rest\"]\n",
    "\n",
    "rest_tiers = pd.cut(\n",
    "    rest_df[\"cum_share\"],\n",
    "    bins=bins,\n",
    "    labels=labels,\n",
    "    include_lowest=True\n",
    ").astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_labels = pd.Series({sku: f\"solo::{sku}\"} for sku in top5)\n",
    "solo_labels = pd.Series({sku: f\"solo::{sku}\" for sku in top5}, name=\"tier\", dtype=\"string\")\n",
    "\n",
    "rest_labels = pd.Series(rest_tiers.values, index=rest_df[\"SKU\"].values, name=\"tier\", dtype=\"string\")\n",
    "\n",
    "sku_tier = pd.concat([solo_labels, rest_labels])\n",
    "sku_tier = sku_tier.astype(\"string\")\n",
    "\n",
    "sku_tier.name = \"tier\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiered = monthly.merge(sku_tier.to_frame(), left_on=\"SKU\", right_index=True, how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # total volume per SKU (use your monthly/weekly aggregated frame)\n",
    "# sku_vol = monthly.groupby(\"SKU\")[\"Quantity\"].sum().sort_values(ascending=False)\n",
    "\n",
    "# # cumulative revenue/volume share\n",
    "# cum_share = (sku_vol.cumsum() / sku_vol.sum())\n",
    "\n",
    "# bins   = [-np.inf, 0.70, 0.95, np.inf]\n",
    "# labels = [\"highest\", \"medium\", \"rest\"]\n",
    "\n",
    "# sku_tier = pd.cut(cum_share, bins=bins, labels=labels, include_lowest=True).astype(str)\n",
    "# sku_tier.name = \"tier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tier\n",
      "rest       835\n",
      "medium     465\n",
      "highest     38\n",
      "Name: count, dtype: Int64\n",
      "tier\n",
      "rest       62.41%\n",
      "medium     34.75%\n",
      "highest     2.84%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sku_tier.value_counts())\n",
    "print((sku_tier.value_counts(normalize=True) * 100).round(2).astype(str) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiered = monthly.merge(sku_tier, left_on=\"SKU\", right_index=True, how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/joelsng/Documents/GitHub/levelsliving-IMS/.venv/lib/python3.9/site-packages (from scikit-learn) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiered[\"Quantity\"] = tiered[\"Quantity\"].clip(lower=1)\n",
    "tiered[\"lag_1\"] = tiered[\"lag_1\"].clip(lower=1)\n",
    "\n",
    "tiered[\"log_qty\"] = np.log1p(tiered[\"Quantity\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = monthly[[\"month_num\", \"year\", \"sku_id\",\"lag_1\", \"lag_2\", \"lag_3\", \"month_sin\", \"month_cos\"]]\n",
    "y = monthly[\"Quantity\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_core_api(\n",
    "    df_tier,\n",
    "    feat=(\"month_num\", \"year\", \"sku_id\", \"lag_1\", \"lag_2\", \"lag_3\", \"month_sin\", \"month_cos\"),\n",
    "):\n",
    "    # Drop rows that cannot form lag_1\n",
    "    df_tier = df_tier.dropna(subset=[\"lag_1\"]).reset_index(drop=True)\n",
    "\n",
    "    # If too small, return 6-tuple with features so callers can unpack safely\n",
    "    if len(df_tier) < 20:\n",
    "        return None, None, None, None, None, list(feat)\n",
    "\n",
    "    X = df_tier[list(feat)].to_numpy(dtype=float)\n",
    "    y = df_tier[\"Quantity\"].to_numpy(dtype=float)\n",
    "\n",
    "    # 80/20 split with guards so validation is never empty\n",
    "    split_idx = int(len(df_tier) * 0.8)\n",
    "    if split_idx <= 0:\n",
    "        split_idx = 1\n",
    "    if split_idx >= len(df_tier):\n",
    "        split_idx = len(df_tier) - 1\n",
    "\n",
    "    X_tr, X_va = X[:split_idx], X[split_idx:]\n",
    "    y_tr, y_va = y[:split_idx], y[split_idx:]\n",
    "\n",
    "    dtr = xgb.DMatrix(X_tr, label=y_tr, feature_names=list(feat))\n",
    "    dva = xgb.DMatrix(X_va, label=y_va, feature_names=list(feat))\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eta\": 0.1,\n",
    "        \"max_depth\": 4,\n",
    "        \"subsample\": 0.9,\n",
    "        \"colsample_bytree\": 0.9,\n",
    "        \"eval_metric\": [\"rmse\", \"mae\"],\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "    ev = [(dtr, \"train\"), (dva, \"valid\")]\n",
    "    bst = xgb.train(\n",
    "        params,\n",
    "        dtr,\n",
    "        num_boost_round=500,\n",
    "        evals=ev,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    # Predict using best iteration if available\n",
    "    best_iter = getattr(bst, \"best_iteration\", None)\n",
    "    if best_iter is None:\n",
    "        pred = bst.predict(dva)\n",
    "    else:\n",
    "        pred = bst.predict(dva, iteration_range=(0, best_iter + 1))\n",
    "\n",
    "    mae = float(np.mean(np.abs(y_va - pred)))\n",
    "    rmse = float(np.sqrt(np.mean((y_va - pred) ** 2)))\n",
    "    mape = float(np.mean(np.abs((y_va - pred) / np.clip(y_va, 1e-8, None))) * 100)\n",
    "    smape = float(100 * np.mean(2 * np.abs(y_va - pred) / (np.abs(y_va) + np.abs(pred) + 1e-8)))\n",
    "\n",
    "    return bst, mae, rmse, mape, smape, list(feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slugify_tier(tier: str) -> str:\n",
    "    s = re.sub(r\"[^A-Za-z0-9]+\", \"_\", str(tier)).strip(\"_\")\n",
    "    return s or \"tier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rest] MAE=0.227  RMSE=0.477  MAPE=11.36%  SMAPE=15.15%  (best_iter=0)\n",
      "[medium] MAE=1.596  RMSE=3.122  MAPE=90.37%  SMAPE=59.44%  (best_iter=4)\n",
      "[highest] MAE=5.151  RMSE=6.476  MAPE=115.23%  SMAPE=54.23%  (best_iter=44)\n",
      "                               SKU                     Month  predicted_qty  \\\n",
      "0                         10031400 2022-11-30 00:00:00+00:00            1.0   \n",
      "1                         10031737 2023-01-31 00:00:00+00:00            1.0   \n",
      "2                         10061281 2022-08-31 00:00:00+00:00            1.0   \n",
      "3                         10077190 2023-03-31 00:00:00+00:00            1.0   \n",
      "4                      10097234-AD 2025-03-31 00:00:00+00:00            1.0   \n",
      "5                         10098455 2022-07-31 00:00:00+00:00            1.0   \n",
      "6                         10152878 2023-07-31 00:00:00+00:00            1.0   \n",
      "7                         10153754 2022-11-30 00:00:00+00:00            1.0   \n",
      "8                         10178643 2023-08-31 00:00:00+00:00            1.0   \n",
      "9                         10191379 2023-08-31 00:00:00+00:00            1.0   \n",
      "10                        10208197 2023-07-31 00:00:00+00:00            1.0   \n",
      "11                        10212409 2023-01-31 00:00:00+00:00            1.0   \n",
      "12                        10217526 2023-07-31 00:00:00+00:00            1.0   \n",
      "13                        10219409 2024-04-30 00:00:00+00:00            1.0   \n",
      "14                        10227012 2022-08-31 00:00:00+00:00            1.0   \n",
      "15                        10231404 2023-11-30 00:00:00+00:00            1.0   \n",
      "16                        10256794 2023-04-30 00:00:00+00:00            1.0   \n",
      "17                        10294095 2022-06-30 00:00:00+00:00            1.0   \n",
      "18  10294095 (70046002 + 70046003) 2023-04-30 00:00:00+00:00            1.0   \n",
      "19                        10332807 2023-05-31 00:00:00+00:00            1.0   \n",
      "\n",
      "    tier  \n",
      "0   rest  \n",
      "1   rest  \n",
      "2   rest  \n",
      "3   rest  \n",
      "4   rest  \n",
      "5   rest  \n",
      "6   rest  \n",
      "7   rest  \n",
      "8   rest  \n",
      "9   rest  \n",
      "10  rest  \n",
      "11  rest  \n",
      "12  rest  \n",
      "13  rest  \n",
      "14  rest  \n",
      "15  rest  \n",
      "16  rest  \n",
      "17  rest  \n",
      "18  rest  \n",
      "19  rest  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def slugify_tier(tier: str) -> str:\n",
    "    s = re.sub(r\"[^A-Za-z0-9]+\", \"_\", str(tier)).strip(\"_\")\n",
    "    return s or \"tier\"\n",
    "\n",
    "models = {}\n",
    "metrics = []\n",
    "future_all = []\n",
    "\n",
    "cur_dir = Path(__file__).resolve().parents[1] if \"__file__\" in globals() else Path.cwd()\n",
    "save_dir = cur_dir / \"models\"\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tier_list = tiered[\"tier\"].dropna().astype(str).unique().tolist()\n",
    "\n",
    "for tier in tier_list:\n",
    "    sub = tiered.loc[tiered[\"tier\"] == tier].copy()\n",
    "    if sub.empty:\n",
    "        print(f\"[{tier}] skipped (no rows)\")\n",
    "        continue\n",
    "\n",
    "    bst, mae, rmse, mape, smape, feat = train_xgb_core_api(sub)\n",
    "    if bst is None:\n",
    "        print(f\"[{tier}] skipped (not enough data)\")\n",
    "        continue\n",
    "\n",
    "    # Stable, safe filename per tier (e.g., solo__SKU_123)\n",
    "    tier_slug = slugify_tier(tier)\n",
    "    model_path = save_dir / f\"xgb_sku_{tier_slug}_model.json\"\n",
    "    bst.save_model(model_path)\n",
    "    models[tier] = (bst, feat)\n",
    "\n",
    "    # best_iteration can be None if early stopping not triggered\n",
    "    best_iter = getattr(bst, \"best_iteration\", None)\n",
    "    if best_iter is None:\n",
    "        print(f\"[{tier}] MAE={mae:.3f}  RMSE={rmse:.3f}  MAPE={mape:.2f}%  SMAPE={smape:.2f}%\")\n",
    "    else:\n",
    "        print(f\"[{tier}] MAE={mae:.3f}  RMSE={rmse:.3f}  MAPE={mape:.2f}%  SMAPE={smape:.2f}%  (best_iter={best_iter})\")\n",
    "\n",
    "    # ---------- Build next-month features per SKU in this tier ----------\n",
    "    sub = sub.sort_values([\"SKU\", \"Month\"])\n",
    "    last_rows = sub.groupby(\"SKU\", as_index=False).tail(1).reset_index(drop=True)\n",
    "\n",
    "    def nth_from_end(s, n):\n",
    "        import numpy as np\n",
    "        return s.iloc[-n] if len(s) >= n else np.nan\n",
    "\n",
    "    # Lags computed within this tier; each SKU appears in exactly one tier\n",
    "    lag2_map = sub.groupby(\"SKU\")[\"Quantity\"].apply(lambda s: nth_from_end(s, 2))\n",
    "    lag3_map = sub.groupby(\"SKU\")[\"Quantity\"].apply(lambda s: nth_from_end(s, 3))\n",
    "\n",
    "    fut_month = pd.to_datetime(last_rows[\"Month\"]) + pd.offsets.MonthEnd(1)\n",
    "    fut_month_num = fut_month.dt.month\n",
    "\n",
    "    future = pd.DataFrame({\n",
    "        \"SKU\": last_rows[\"SKU\"],\n",
    "        \"Month\": fut_month,\n",
    "        \"month_num\": fut_month_num,\n",
    "        \"year\": fut_month.dt.year,\n",
    "        \"sku_id\": last_rows[\"sku_id\"],\n",
    "        \"lag_1\": last_rows[\"Quantity\"],\n",
    "        \"lag_2\": last_rows[\"SKU\"].map(lag2_map),\n",
    "        \"lag_3\": last_rows[\"SKU\"].map(lag3_map),\n",
    "        \"month_sin\": np.sin(2 * np.pi * fut_month_num / 12),\n",
    "        \"month_cos\": np.cos(2 * np.pi * fut_month_num / 12),\n",
    "    })\n",
    "\n",
    "    # Ensure exact feature order expected by this tierâ€™s model\n",
    "    for c in feat:\n",
    "        if c not in future.columns:\n",
    "            future[c] = np.nan\n",
    "    future = future[list(feat)]\n",
    "\n",
    "    dfut = xgb.DMatrix(future.to_numpy(dtype=float), feature_names=list(feat))\n",
    "\n",
    "    # Respect early-stopping boundary if present\n",
    "    if best_iter is None:\n",
    "        preds = models[tier][0].predict(dfut)\n",
    "    else:\n",
    "        preds = models[tier][0].predict(dfut, iteration_range=(0, best_iter + 1))\n",
    "\n",
    "    out = last_rows[[\"SKU\"]].copy()\n",
    "    out[\"Month\"] = fut_month\n",
    "    out[\"predicted_qty\"] = preds\n",
    "    out[\"tier\"] = tier\n",
    "    future_all.append(out[[\"SKU\", \"Month\", \"predicted_qty\", \"tier\"]])\n",
    "\n",
    "future_preds = pd.concat(future_all, ignore_index=True)\n",
    "print(future_preds.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
